#!/usr/bin/python
# -*- coding: utf-8 -*-

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import random

class GFocalLoss(nn.Module):

    def __init__(self, gamma=2.0, loss_weight=1.0):
        super(GFocalLoss, self).__init__()
        self.gamma = gamma
        self.loss_weight = loss_weight

    def forward(self, pred, target, mask):
        #pred, target = pred[mask], target[mask]
        target = target.type_as(pred)
        scales = (16**2, 8**2, 4**2, 2**2, 1**2)
        small = pred.size(1) / 6 / np.sum(scales)
        scales = np.cumsum([int(i*small*6) for i in scales]).tolist()
        scales.insert(0,0)
        for i in range(len(scales)-1):
            lo, hi = scales[i], scales[i+1]
            cur_pred, cur_target = pred[:,lo:hi,:], target[:,lo:hi,:]
            focal_weight = (cur_target - cur_pred.sigmoid()).abs().pow(self.gamma)
            cur_loss = F.binary_cross_entropy_with_logits(cur_pred, cur_target, reduction='none') * focal_weight
            cur_loss = cur_loss.sum() / (cur_target>0).float().sum()
            if i == 0:
                loss = cur_loss
            else:
                loss = loss + cur_loss
        return loss / (len(scales)-1) * self.loss_weight
